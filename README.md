# DATA ANALYTICS #1
# Data Cleansing

Data cleansing, also known as data cleaning or data scrubbing, is a critical process in data analytics aimed at cleaning and preparing data for analysis. Its primary goal is to identify, correct, and eliminate errors, inconsistencies, or inaccuracies in a dataset. Clean and high-quality data is the fundamental basis for obtaining accurate and meaningful analysis results. 

Here are some steps and explanations of data cleansing in data analytics :
### 1. Identifying Dirty Data
  - Data can become dirty due to various reasons such as human errors, equipment issues, communication disruptions, or inconsistent formats. The first step is to identify the types of errors or discrepancies present in the dataset.

    ![image](https://github.com/NinysRevalyna/data_analytics_1/assets/72516143/b7c75a4e-1725-4a72-a12f-2f74466f6fcc)

### 2. Handling Missing Values
- Data cleansing involves addressing missing values. This can be done by filling in missing values with appropriate values (mean, median, or mode) or by removing rows containing missing values if feasible.

  ![image](https://github.com/NinysRevalyna/data_analytics_1/assets/72516143/0da35a5a-1236-4739-9d91-a29f449254e8)

### 3. Removing Duplicates
- Duplicate data may appear multiple times in a dataset. Duplicates must be identified and removed to ensure that analysis does not yield distorted results.

  ![image](https://github.com/NinysRevalyna/data_analytics_1/assets/72516143/11f62469-132b-43fb-bc0d-e5bd0b262a78)

### 4. Addressing Noise and Outliers
- Noise is random, irrelevant data or recording errors that do not represent useful information. Outliers are extreme values that may not be representative of the general population. Both of these issues need to be addressed to prevent them from affecting analysis results.

### 5. Handling Inconsistent Data
- Data may have inconsistent formats, such as varying date notations or non-uniform measurement units. These need to be standardized to consistent formats to enable data to be compared and used in analysis.

### 6. Data Validation
- Data validation involves checking data integrity, including validity rules and referential integrity. For example, verifying whether all identification numbers are unique or if data is logically sound.

### 7. Data Standardization
- Data from various sources may have different formats and schemas. Data cleansing can involve standardizing data into a uniform format for easier analysis.

### 8. Documenting Changes
- It is important to document all changes made to the dataset during the data cleansing process. This helps prevent information loss and facilitates communication within the analysis team.

Data cleansing is a crucial step in the data analytics lifecycle because it can have a significant impact on the accuracy of analysis results. Without clean data, analyses can produce serious errors and incorrect conclusions. Therefore, systematic data investigation and refinement are vital steps in data preparation for further analysis.




